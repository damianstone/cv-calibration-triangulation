{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get extrinsic params using robust calibration paper\n",
    "Output: R, T between camera pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if '/Users/damianstone/Documents/Code/tennis-project/post-triangulation/' not in sys.path:\n",
    "  sys.path.append('/Users/damianstone/Documents/Code/tennis-project/post-triangulation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "\n",
    "BASE_PATH = '/Users/damianstone/Documents/Code/tennis-project/post-triangulation/'\n",
    "IMAGE_BASE_PATH = f'{BASE_PATH}/images/'\n",
    "INTRINSIC_PARAMS_FILE_NAME = 'intrinsic_params.json'\n",
    "\n",
    "STEREO_PAIRS = {\n",
    "    \"STEREO_1\": (\"left_stereo_1/*.png\", \"right_stereo_1/*.png\"),  # CAM_1 & CAM_2\n",
    "    \"STEREO_2\": (\"left_stereo_2/*.png\", \"right_stereo_2/*.png\")   # CAM_3 & CAM_4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CAM_1_LEFT': {'fx': 1800.0,\n",
       "  'fy': 1805.0,\n",
       "  'cx': 1920.0,\n",
       "  'cy': 1080.0,\n",
       "  'D': [-0.25, 0.05, 0.0, 0.0, -0.02],\n",
       "  'K': [[1800.0, 0, 1920.0], [0, 1805.0, 1080.0], [0, 0, 1]]},\n",
       " 'CAM_2_RIGHT': {'fx': 1795.0,\n",
       "  'fy': 1800.0,\n",
       "  'cx': 1918.0,\n",
       "  'cy': 1078.0,\n",
       "  'D': [-0.23, 0.04, 0.0, 0.0, -0.015],\n",
       "  'K': [[1795.0, 0, 1918.0], [0, 1800.0, 1078.0], [0, 0, 1]]},\n",
       " 'CAM_3_LEFT': {'fx': 1810.0,\n",
       "  'fy': 1812.0,\n",
       "  'cx': 1925.0,\n",
       "  'cy': 1082.0,\n",
       "  'D': [-0.27, 0.06, 0.0, 0.0, -0.018],\n",
       "  'K': [[1810.0, 0, 1925.0], [0, 1812.0, 1082.0], [0, 0, 1]]},\n",
       " 'CAM_4_RIGHT': {'fx': 1805.0,\n",
       "  'fy': 1810.0,\n",
       "  'cx': 1922.0,\n",
       "  'cy': 1081.0,\n",
       "  'D': [-0.24, 0.05, 0.0, 0.0, -0.017],\n",
       "  'K': [[1805.0, 0, 1922.0], [0, 1810.0, 1081.0], [0, 0, 1]]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load intrinsic parameters\n",
    "with open(f'{BASE_PATH}/data/{INTRINSIC_PARAMS_FILE_NAME}', \"r\") as file:\n",
    "    camera_data = json.load(file)\n",
    "\n",
    "camera_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# --- Main functions implementing the paperâ€™s steps ---\n",
    "\n",
    "def white_pixel_detector(image, sigma_l=128, sigma_d=20, tau=8):\n",
    "    \"\"\"\n",
    "    Implements Section 3.1: Detect white court-line pixels.\n",
    "    (Use brightness and neighbor tests; here a simplified version.)\n",
    "    \"\"\"\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # Simple threshold-based candidate selection (placeholder)\n",
    "    mask = (gray >= sigma_l).astype(np.uint8) * 255\n",
    "    return mask\n",
    "\n",
    "def hough_line_detection(white_mask, threshold=100, min_line_length=50, max_line_gap=5):\n",
    "    \"\"\"\n",
    "    Section 3.2.1: Extract candidate court lines using Hough transform.\n",
    "    \"\"\"\n",
    "    lines = cv.HoughLinesP(white_mask, 1, np.pi/180, threshold,\n",
    "                           minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    return lines\n",
    "\n",
    "def refine_lines(candidate_lines):\n",
    "    \"\"\"\n",
    "    Section 3.2.2: Refine line parameters using least squares fitting on nearby white pixels.\n",
    "    (Placeholder: return candidate_lines as-is.)\n",
    "    \"\"\"\n",
    "    return candidate_lines\n",
    "\n",
    "def court_model_fitting(refined_lines, court_model):\n",
    "    \"\"\"\n",
    "    Section 3.3: Combinatorial search to assign candidate lines to the court model.\n",
    "    Computes intersection points and solves a linear system to estimate the 8-parameter homography H.\n",
    "    (Placeholder: returns an identity matrix.)\n",
    "    \"\"\"\n",
    "    H = np.eye(3)\n",
    "    return H\n",
    "\n",
    "def calibration_rejection_test(H):\n",
    "    \"\"\"\n",
    "    Section 3.3.2: Quickly reject physically impossible solutions using non-isotropic scaling test.\n",
    "    (Placeholder: always accepts.)\n",
    "    \"\"\"\n",
    "    return True\n",
    "\n",
    "def evaluate_model_support(H, white_mask, court_model):\n",
    "    \"\"\"\n",
    "    Section 3.3.3: Project the court model with H, sample along model lines, and compute a matching score.\n",
    "    (Placeholder: returns a dummy score.)\n",
    "    \"\"\"\n",
    "    score = 1.0\n",
    "    return score\n",
    "\n",
    "def calibrate_camera(image, court_model):\n",
    "    \"\"\"\n",
    "    Full calibration for one camera on a single frame:\n",
    "      - Detect white pixels\n",
    "      - Extract & refine line candidates\n",
    "      - Perform model fitting via combinatorial search\n",
    "      - Reject and evaluate candidate H, and return the best H.\n",
    "    \"\"\"\n",
    "    white_mask = white_pixel_detector(image)\n",
    "    candidate_lines = hough_line_detection(white_mask)\n",
    "    refined_lines = refine_lines(candidate_lines)\n",
    "    H = court_model_fitting(refined_lines, court_model)\n",
    "    if calibration_rejection_test(H):\n",
    "        score = evaluate_model_support(H, white_mask, court_model)\n",
    "        # In a full implementation, search over multiple assignments and choose the best H.\n",
    "        return H  # Placeholder: return H directly\n",
    "    return None\n",
    "\n",
    "def stereo_extrinsics_from_homographies(H_left, H_right):\n",
    "    \"\"\"\n",
    "    Compute the relative transformation between two cameras from their estimated homographies.\n",
    "    A simple approach: H_rel = H_right * inv(H_left)\n",
    "    (Further decomposition into R and T can be done if needed.)\n",
    "    \"\"\"\n",
    "    H_rel = H_right @ np.linalg.inv(H_left)\n",
    "    return H_rel\n",
    "\n",
    "def calibrate_stereo_pair(images_left, images_right, court_model):\n",
    "    \"\"\"\n",
    "    Calibrate a stereo pair by processing multiple frames:\n",
    "      - For each camera, run the single-camera calibration (using the court model) over several frames.\n",
    "      - For simplicity, select the first successful H from each camera.\n",
    "      - Compute the relative extrinsics.\n",
    "    \"\"\"\n",
    "    H_left, H_right = None, None\n",
    "    for img_l, img_r in zip(images_left, images_right):\n",
    "        H_l = calibrate_camera(img_l, court_model)\n",
    "        H_r = calibrate_camera(img_r, court_model)\n",
    "        if H_l is not None and H_r is not None:\n",
    "            H_left, H_right = H_l, H_r\n",
    "            break\n",
    "    if H_left is None or H_right is None:\n",
    "        return None\n",
    "    H_rel = stereo_extrinsics_from_homographies(H_left, H_right)\n",
    "    return H_left, H_right, H_rel\n",
    "\n",
    "def calibrate_four_cameras(images_left1, images_right1, images_left2, images_right2, court_model):\n",
    "    \"\"\"\n",
    "    Adapted for 4 cameras (two stereo pairs):\n",
    "      - Calibrate stereo pair 1 (e.g., left side of court): CAM_1 & CAM_2.\n",
    "      - Calibrate stereo pair 2 (e.g., right side of court): CAM_3 & CAM_4.\n",
    "    \"\"\"\n",
    "    H_left1, H_right1, H_rel1 = calibrate_stereo_pair(images_left1, images_right1, court_model)\n",
    "    H_left2, H_right2, H_rel2 = calibrate_stereo_pair(images_left2, images_right2, court_model)\n",
    "    return {\n",
    "        \"Stereo_Pair_1\": {\"H_left\": H_left1, \"H_right\": H_right1, \"H_rel\": H_rel1},\n",
    "        \"Stereo_Pair_2\": {\"H_left\": H_left2, \"H_right\": H_right2, \"H_rel\": H_rel2}\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "def pipeline(folder_left1, folder_right1, folder_left2, folder_right2, court_model, intrinsics):\n",
    "    \"\"\"\n",
    "    Calibrates four cameras (two stereo pairs) using the court model.\n",
    "    \n",
    "    Parameters:\n",
    "      folder_left1, folder_right1: paths for stereo pair 1 (e.g., CAM_1 and CAM_2)\n",
    "      folder_left2, folder_right2: paths for stereo pair 2 (e.g., CAM_3 and CAM_4)\n",
    "      court_model: the predefined court model (real-world line positions)\n",
    "      intrinsics: a dictionary with keys \"CAM_1\", \"CAM_2\", \"CAM_3\", \"CAM_4\". Each entry should contain:\n",
    "                  \"K\": the intrinsic matrix (3x3) and\n",
    "                  \"D\": the distortion coefficients (unused here).\n",
    "    \n",
    "    Returns:\n",
    "      A dictionary containing for each stereo pair:\n",
    "         - P_left: projection matrix for the left camera (K_left * [I|0])\n",
    "         - P_right: projection matrix for the right camera (K_right * [R|T])\n",
    "         - R: rotation matrix between the pair\n",
    "         - T: translation vector between the pair\n",
    "    \"\"\"\n",
    "    images_left1 = sorted(glob.glob(f\"{folder_left1}/*.png\"))\n",
    "    images_right1 = sorted(glob.glob(f\"{folder_right1}/*.png\"))\n",
    "    images_left2 = sorted(glob.glob(f\"{folder_left2}/*.png\"))\n",
    "    images_right2 = sorted(glob.glob(f\"{folder_right2}/*.png\"))\n",
    "    \n",
    "    # Calibrate stereo pair 1 (CAM_1 and CAM_2)\n",
    "    R1, T1 = calibrate_stereo_pair(images_left1, images_right1, court_model,\n",
    "                                   intrinsics[\"CAM_1\"], intrinsics[\"CAM_2\"])\n",
    "    # Calibrate stereo pair 2 (CAM_3 and CAM_4)\n",
    "    R2, T2 = calibrate_stereo_pair(images_left2, images_right2, court_model,\n",
    "                                   intrinsics[\"CAM_3\"], intrinsics[\"CAM_4\"])\n",
    "    \n",
    "    # Compute projection matrices: P = K * [R|T]\n",
    "    # For left cameras, we assume identity rotation and zero translation.\n",
    "    P_left1 = intrinsics[\"CAM_1\"][\"K\"] @ np.hstack((np.eye(3), np.zeros((3,1))))\n",
    "    P_right1 = intrinsics[\"CAM_2\"][\"K\"] @ np.hstack((R1, T1))\n",
    "    \n",
    "    P_left2 = intrinsics[\"CAM_3\"][\"K\"] @ np.hstack((np.eye(3), np.zeros((3,1))))\n",
    "    P_right2 = intrinsics[\"CAM_4\"][\"K\"] @ np.hstack((R2, T2))\n",
    "    \n",
    "    results = {\n",
    "        \"Stereo_Pair_1\": {\n",
    "            \"P_left\": P_left1,\n",
    "            \"P_right\": P_right1,\n",
    "            \"R\": R1,\n",
    "            \"T\": T1\n",
    "        },\n",
    "        \"Stereo_Pair_2\": {\n",
    "            \"P_left\": P_left2,\n",
    "            \"P_right\": P_right2,\n",
    "            \"R\": R2,\n",
    "            \"T\": T2\n",
    "        }\n",
    "    }\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
